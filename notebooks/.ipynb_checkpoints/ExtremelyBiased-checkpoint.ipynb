{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>content</th>\n",
       "      <th>count</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Um recurso da Procuradoria-Geral da República ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>STF decide hoje se vídeo de Aécio explicando m...</td>\n",
       "      <td>http://www.sensacionalista.com.br/2017/09/26/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Há uma certa magia em viajar de trem pela Grã-...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15 destinos para conhecer de trem</td>\n",
       "      <td>http://bit.ly/2g8k2XR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Site Lança Cardápio Fit/Light (low-carb) e é N...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Site Lança Cardápio Fit (low-carb) e é Nova Se...</td>\n",
       "      <td>http://g3noticias.com.br/site_lanca_cardapio_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A hashtag #posteseuviralata alcançou o topo Tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>A hashtag #posteseuviralata está enchendo o Tw...</td>\n",
       "      <td>http://bzfd.it/2yvqIu3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>\"O que não me explicaram no dia da entrevista ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Mulher acusa laboratório Fleury de racismo por...</td>\n",
       "      <td>https://www.buzzfeed.com/tatianafarah/mulher-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Parabéns, você deveria ir ao cinema! Você sabe...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Você deveria ir ao cinema?</td>\n",
       "      <td>http://bzfd.it/2ysGJ3W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Aprovada em silêncio aos 45 minutos do segundo...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Em silêncio, reforma eleitoral criou censura n...</td>\n",
       "      <td>http://bzfd.it/2xl7lin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Mas não espere que Kesha conte algum segredo d...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Kesha falou sobre que tipo de amiga a Taylor S...</td>\n",
       "      <td>http://bzfd.it/2yrVggv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Segundo deu em primeira mão o colunista Ancelm...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Mudança na Rouanet proíbe a Bíblia, que está c...</td>\n",
       "      <td>http://www.sensacionalista.com.br/2017/10/06/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Com as eleições presidenciais se aproximando, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Facebook retira comentários e deixa apenas bot...</td>\n",
       "      <td>http://www.sensacionalista.com.br/2017/10/06/f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id                                            content  count  id  \\\n",
       "0            5  Um recurso da Procuradoria-Geral da República ...      1   1   \n",
       "1            1  Há uma certa magia em viajar de trem pela Grã-...      1   2   \n",
       "2            3  Site Lança Cardápio Fit/Light (low-carb) e é N...      1   3   \n",
       "3            1  A hashtag #posteseuviralata alcançou o topo Tr...      1   4   \n",
       "4            1  \"O que não me explicaram no dia da entrevista ...      1   5   \n",
       "5            3  Parabéns, você deveria ir ao cinema! Você sabe...      1   6   \n",
       "6            1  Aprovada em silêncio aos 45 minutos do segundo...      1   7   \n",
       "7            3  Mas não espere que Kesha conte algum segredo d...      1   8   \n",
       "8            5  Segundo deu em primeira mão o colunista Ancelm...      1   9   \n",
       "9            5  Com as eleições presidenciais se aproximando, ...      1  10   \n",
       "\n",
       "                                               title  \\\n",
       "0  STF decide hoje se vídeo de Aécio explicando m...   \n",
       "1                  15 destinos para conhecer de trem   \n",
       "2  Site Lança Cardápio Fit (low-carb) e é Nova Se...   \n",
       "3  A hashtag #posteseuviralata está enchendo o Tw...   \n",
       "4  Mulher acusa laboratório Fleury de racismo por...   \n",
       "5                         Você deveria ir ao cinema?   \n",
       "6  Em silêncio, reforma eleitoral criou censura n...   \n",
       "7  Kesha falou sobre que tipo de amiga a Taylor S...   \n",
       "8  Mudança na Rouanet proíbe a Bíblia, que está c...   \n",
       "9  Facebook retira comentários e deixa apenas bot...   \n",
       "\n",
       "                                                 url  \n",
       "0  http://www.sensacionalista.com.br/2017/09/26/s...  \n",
       "1                              http://bit.ly/2g8k2XR  \n",
       "2  http://g3noticias.com.br/site_lanca_cardapio_f...  \n",
       "3                             http://bzfd.it/2yvqIu3  \n",
       "4  https://www.buzzfeed.com/tatianafarah/mulher-a...  \n",
       "5                             http://bzfd.it/2ysGJ3W  \n",
       "6                             http://bzfd.it/2xl7lin  \n",
       "7                             http://bzfd.it/2yrVggv  \n",
       "8  http://www.sensacionalista.com.br/2017/10/06/m...  \n",
       "9  http://www.sensacionalista.com.br/2017/10/06/f...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"http://fake-news-detector-api.herokuapp.com/links/all\")\n",
    "\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of biased samples 49\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df.dropna(subset=[\"title\"], inplace=True)\n",
    "df.dropna(subset=[\"content\"], inplace=True)\n",
    "\n",
    "df[\"is_biased\"] = [cid == 4 for cid in df[\"category_id\"]]\n",
    "\n",
    "X = df[\"title\"] + df[\"content\"]\n",
    "y = df[\"is_biased\"]\n",
    "\n",
    "print(\"Number of biased samples\", len(df[df[\"is_biased\"] == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.451 f1 0.443 positive_recall 0.988 total weighted 2.869 MultinomialNB\n",
      "accuracy 0.628 f1 0.559 positive_recall 0.74 total weighted 2.667 BernoulliNB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, make_scorer, recall_score\n",
    "\n",
    "def test_classifier(clf_):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('sampling', RandomUnderSampler()),\n",
    "        ('clf', clf_)\n",
    "    ])\n",
    "    \n",
    "    clf = pipeline.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    avg_f1 = (f1_score(y_test, y_pred, pos_label=False) + f1_score(y_test, y_pred)) / 2\n",
    "    positive_recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, avg_f1, positive_recall\n",
    "    \n",
    "    \n",
    "def test_classifier_avg(name, clf):\n",
    "    times = 5\n",
    "    total_accuracy = 0\n",
    "    total_f1 = 0\n",
    "    total_positive_recall = 0\n",
    "    \n",
    "    for i in range(0, times):\n",
    "        accuracy, f1, positive_recall = test_classifier(clf)\n",
    "        total_accuracy += accuracy\n",
    "        total_f1 += f1\n",
    "        total_positive_recall += positive_recall\n",
    "    \n",
    "    print(\"accuracy\", round(total_accuracy / times, 3),\n",
    "          \"f1\", round(total_f1 / times, 3),\n",
    "          \"positive_recall\", round(total_positive_recall / times, 3),\n",
    "          \"total weighted\", round((total_accuracy + total_f1 + total_positive_recall * 2) / times, 3),\n",
    "          name\n",
    "         )\n",
    "\n",
    "\n",
    "test_classifier_avg(\"MultinomialNB\", MultinomialNB())\n",
    "test_classifier_avg(\"BernoulliNB\", BernoulliNB())\n",
    "test_classifier_avg(\"MultiLayerPerceptron\", MLPClassifier(solver='adam', max_iter=1000))\n",
    "test_classifier_avg(\"KNN\", KNeighborsClassifier())\n",
    "test_classifier_avg(\"SGDClassifier\", SGDClassifier(max_iter=1000))\n",
    "test_classifier_avg(\"RandomForest\", RandomForestClassifier())\n",
    "test_classifier_avg(\"DecisionTreeClassifier\", DecisionTreeClassifier())\n",
    "test_classifier_avg(\"SVC\", SVC(kernel='rbf', probability=True))\n",
    "# test_classifier_avg(\"VotingClassifier\", VotingClassifier(estimators=[\n",
    "#             ('MultinomialNB', MultinomialNB()),\n",
    "#             (\"MultiLayerPerceptron\", MLPClassifier(solver='adam', max_iter=1000)),\n",
    "#             (\"SVC\", SVC(kernel='rbf', probability=True))\n",
    "#         ]))\n",
    "# test_classifier_avg(\"VotingClassifier2\", VotingClassifier(estimators=[\n",
    "#             ('MultinomialNB', MultinomialNB()),\n",
    "#             (\"MultiLayerPerceptron\", MLPClassifier(solver='adam', max_iter=1000)),\n",
    "#             (\"SDG\", SGDClassifier(max_iter=1000))\n",
    "#         ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score 0.52973168963\n",
      "clf__activation: 'tanh'\n",
      "clf__solver: 'lbfgs'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(2,2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('sampling', RandomUnderSampler()),\n",
    "    ('clf', MLPClassifier(max_iter=10000, solver=\"adam\", activation=\"relu\"))\n",
    "])\n",
    "\n",
    "parameters = {'clf__solver': [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "              'clf__activation': [\"relu\", \"tanh\"],\n",
    "}\n",
    "\n",
    "def my_custom_loss_func(y_test, y_pred):\n",
    "    return (f1_score(y_test, y_pred, pos_label=False) + f1_score(y_test, y_pred)) / 2 + recall_score(y_test, y_pred)\n",
    "\n",
    "scoring = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
    "\n",
    "gs_clf = GridSearchCV(pipeline, parameters, n_jobs=-1, scoring=scoring)\n",
    "gs_clf = gs_clf.fit(X, y)\n",
    "\n",
    "print(\"Best score\", gs_clf.best_score_)\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score 0.144670050761\n",
      "clf: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "def my_custom_loss_func(y_test, y_pred):\n",
    "    return (f1_score(y_test, y_pred, pos_label=False) + f1_score(y_test, y_pred)) / 2 + recall_score(y_test, y_pred)\n",
    "\n",
    "scoring = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(2,2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', SVC(kernel='rbf', probability=True))\n",
    "])\n",
    "\n",
    "parameters = {'clf': [\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "#     MLPClassifier(max_iter=1000),\n",
    "    SGDClassifier(max_iter=1000),\n",
    "    RandomForestClassifier()\n",
    "]}\n",
    "\n",
    "gs_clf = GridSearchCV(pipeline, parameters, n_jobs=-1, cv=30, scoring=\"recall\")\n",
    "gs_clf = gs_clf.fit(X, y)\n",
    "\n",
    "print(\"Best score\", gs_clf.best_score_)\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
