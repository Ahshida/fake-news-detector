{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>content</th>\n",
       "      <th>count</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>verified_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Vitória por quatro ou mais gols de diferença.\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>1241</td>\n",
       "      <td>Goleada</td>\n",
       "      <td>http://www.embasamentus.com/goleada/</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>COUNTRY APPLE FRITTER BREAD 1 teaspoon ground ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1240</td>\n",
       "      <td>COUNTRY APPLE FRITTER BREAD 1 teaspoon ground ...</td>\n",
       "      <td>https://www.facebook.com/9recipes/photos/a.696...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>This material may not be published, broadcast,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1239</td>\n",
       "      <td>California teacher slams military members as '...</td>\n",
       "      <td>http://www.foxnews.com/us/2018/01/28/californi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1238</td>\n",
       "      <td>(5) Facebook</td>\n",
       "      <td>https://www.facebook.com/photo.php?fbid=202868...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LOL! Image by Occupy Democrats, LIKE our page ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1237</td>\n",
       "      <td>LOL!</td>\n",
       "      <td>https://www.facebook.com/OccupyDemocrats/photo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1236</td>\n",
       "      <td>(5) Facebook</td>\n",
       "      <td>https://www.facebook.com/Labor411/photos/a.145...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1235</td>\n",
       "      <td>El golpe esclavista</td>\n",
       "      <td>https://t.co/TvN9YxP72s</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Obama be like:</td>\n",
       "      <td>1</td>\n",
       "      <td>1234</td>\n",
       "      <td>Obama be like:</td>\n",
       "      <td>https://www.facebook.com/888888Eight/photos/a....</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>KKKKKKKKKKKKKKKKKKKK É bem isso.</td>\n",
       "      <td>1</td>\n",
       "      <td>1233</td>\n",
       "      <td>KKKKKKKKKKKKKKKKKKKK É bem isso.</td>\n",
       "      <td>https://www.facebook.com/serggom007/posts/1964...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Outra vez eu me sirvo deste menino que faz o t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1232</td>\n",
       "      <td>De Darcy para Lula: chore hoje, lute amanhã - ...</td>\n",
       "      <td>http://www.tijolaco.com.br/blog/de-darcy-para-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id                                            content  count  \\\n",
       "0            2    Vitória por quatro ou mais gols de diferença.\\n      1   \n",
       "1            1  COUNTRY APPLE FRITTER BREAD 1 teaspoon ground ...      1   \n",
       "2            4  This material may not be published, broadcast,...      1   \n",
       "3            5                                                         1   \n",
       "4            4  LOL! Image by Occupy Democrats, LIKE our page ...      1   \n",
       "5            2                                                         1   \n",
       "6            1                                               None      1   \n",
       "7            5                                     Obama be like:      1   \n",
       "8            1                   KKKKKKKKKKKKKKKKKKKK É bem isso.      1   \n",
       "9            1  Outra vez eu me sirvo deste menino que faz o t...      1   \n",
       "\n",
       "     id                                              title  \\\n",
       "0  1241                                            Goleada   \n",
       "1  1240  COUNTRY APPLE FRITTER BREAD 1 teaspoon ground ...   \n",
       "2  1239  California teacher slams military members as '...   \n",
       "3  1238                                       (5) Facebook   \n",
       "4  1237                                               LOL!   \n",
       "5  1236                                       (5) Facebook   \n",
       "6  1235                                El golpe esclavista   \n",
       "7  1234                                     Obama be like:   \n",
       "8  1233                   KKKKKKKKKKKKKKKKKKKK É bem isso.   \n",
       "9  1232  De Darcy para Lula: chore hoje, lute amanhã - ...   \n",
       "\n",
       "                                                 url  verified_category_id  \n",
       "0               http://www.embasamentus.com/goleada/                   NaN  \n",
       "1  https://www.facebook.com/9recipes/photos/a.696...                   NaN  \n",
       "2  http://www.foxnews.com/us/2018/01/28/californi...                   NaN  \n",
       "3  https://www.facebook.com/photo.php?fbid=202868...                   NaN  \n",
       "4  https://www.facebook.com/OccupyDemocrats/photo...                   NaN  \n",
       "5  https://www.facebook.com/Labor411/photos/a.145...                   NaN  \n",
       "6                            https://t.co/TvN9YxP72s                   NaN  \n",
       "7  https://www.facebook.com/888888Eight/photos/a....                   NaN  \n",
       "8  https://www.facebook.com/serggom007/posts/1964...                   NaN  \n",
       "9  http://www.tijolaco.com.br/blog/de-darcy-para-...                   NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"http://fake-news-detector-api.herokuapp.com/links/all\")\n",
    "\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fake news samples 644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df[\"text\"] = df[\"title\"] + ' ' + df[\"content\"]\n",
    "df.dropna(subset=[\"text\"], inplace=True)\n",
    "\n",
    "df[\"is_fakenews\"] = [cid == 2 for cid in df[\"category_id\"]]\n",
    "\n",
    "texts = df[\"text\"]\n",
    "y = df[\"is_fakenews\"]\n",
    "\n",
    "print(\"Number of fake news samples\", len(df[df[\"is_fakenews\"] == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', 'NN'),\n",
       " ('agora', 'NNS'),\n",
       " ('algo', 'VBP'),\n",
       " ('completamente', 'JJ'),\n",
       " ('estranho', 'FW'),\n",
       " ('um', 'JJ'),\n",
       " ('pudim', 'NN')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text = nltk.word_tokenize(\"e agora algo completamente estranho um pudim\", language='portuguese')\n",
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagged_texts[0][0:10] [('goleada', 'NN'), ('vitoria', 'NNS'), ('por', 'VBP'), ('quatro', 'JJ'), ('ou', 'NN'), ('mais', 'NN'), ('gols', 'FW'), ('de', 'FW'), ('diferenca', 'FW'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import unidecode\n",
    "\n",
    "def normalize_tokenize(text):\n",
    "    no_accents = unidecode.unidecode(text)\n",
    "    lowercased = no_accents.lower()\n",
    "    tokenized = nltk.word_tokenize(lowercased, language='portuguese')\n",
    "    tagged = nltk.pos_tag(tokenized)\n",
    "    \n",
    "    return tagged\n",
    "\n",
    "tagged_texts = [ normalize_tokenize(text) for text in texts ]\n",
    "\n",
    "print(\"tagged_texts[0][0:10]\", tagged_texts[0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goleada NN vitoria NNS por VBP quatro JJ ou NN mais NN gols FW de FW diferenca FW . .'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "X = [ \" \".join([text + \" \" + tag for (text, tag) in text_tag]) for text_tag in tagged_texts ] \n",
    "\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.783 f1 0.77 positive_recall 0.929 total weighted 3.411 MultinomialNB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, make_scorer, recall_score\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def test_classifier(clf_):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(strip_accents='ascii', ngram_range=(1, 4), max_df=0.7, min_df=2)),\n",
    "        ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "        ('sampling', RandomUnderSampler()),\n",
    "        ('clf', clf_)\n",
    "    ])\n",
    "    \n",
    "    clf = pipeline.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    avg_f1 = (f1_score(y_test, y_pred, pos_label=False) + f1_score(y_test, y_pred)) / 2\n",
    "    positive_recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, avg_f1, positive_recall\n",
    "    \n",
    "    \n",
    "def test_classifier_avg(name, clf):\n",
    "    times = 3\n",
    "    total_accuracy = 0\n",
    "    total_f1 = 0\n",
    "    total_positive_recall = 0\n",
    "    \n",
    "    for i in range(0, times):\n",
    "        accuracy, f1, positive_recall = test_classifier(clf)\n",
    "        total_accuracy += accuracy\n",
    "        total_f1 += f1\n",
    "        total_positive_recall += positive_recall\n",
    "    \n",
    "    print(\"accuracy\", round(total_accuracy / times, 3),\n",
    "          \"f1\", round(total_f1 / times, 3),\n",
    "          \"positive_recall\", round(total_positive_recall / times, 3),\n",
    "          \"total weighted\", round((total_accuracy + total_f1 + total_positive_recall * 2) / times, 3),\n",
    "          name\n",
    "         )\n",
    "\n",
    "\n",
    "test_classifier_avg(\"MultinomialNB\", MultinomialNB())\n",
    "# test_classifier_avg(\"BernoulliNB\", BernoulliNB())\n",
    "# test_classifier_avg(\"MultiLayerPerceptron\", MLPClassifier(solver='adam', max_iter=1000))\n",
    "# test_classifier_avg(\"KNN\", KNeighborsClassifier())\n",
    "# test_classifier_avg(\"SGDClassifier\", SGDClassifier(max_iter=1000))\n",
    "# test_classifier_avg(\"RandomForest\", RandomForestClassifier())\n",
    "# test_classifier_avg(\"DecisionTreeClassifier\", DecisionTreeClassifier())\n",
    "# test_classifier_avg(\"SVC\", SVC(kernel='rbf', probability=True))\n",
    "# test_classifier_avg(\"VotingClassifier\", VotingClassifier(estimators=[\n",
    "#             ('MultinomialNB', MultinomialNB()),\n",
    "#             (\"MultiLayerPerceptron\", MLPClassifier(solver='adam', max_iter=1000)),\n",
    "#             (\"SVC\", SVC(kernel='rbf', probability=True))\n",
    "#         ]))\n",
    "# test_classifier_avg(\"VotingClassifier2\", VotingClassifier(estimators=[\n",
    "#             ('MultinomialNB', MultinomialNB()),\n",
    "#             (\"MultiLayerPerceptron\", MLPClassifier(solver='adam', max_iter=1000)),\n",
    "#             (\"SDG\", SGDClassifier(max_iter=1000))\n",
    "#         ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score 1.649749671371195\n",
      "clf__alpha: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3), min_df=5, max_df=0.5)),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('sampling', RandomUnderSampler()),\n",
    "    ('clf', MultinomialNB(fit_prior=False))\n",
    "])\n",
    "\n",
    "parameters = {#'tfidf__use_idf': [True, False],\n",
    "              #'vect__ngram_range': [(1, 2), (1, 3)],\n",
    "#               'vect__max_df': [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "#               'vect__min_df': [2, 5, 8, 10],\n",
    "              'clf__alpha': [0.7, 0.9, 1.0],\n",
    "              #'clf__fit_prior': [True, False],\n",
    "}\n",
    "\n",
    "def my_custom_loss_func(y_test, y_pred):\n",
    "    return (f1_score(y_test, y_pred, pos_label=False) + f1_score(y_test, y_pred)) / 2 + recall_score(y_test, y_pred)\n",
    "\n",
    "scoring = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
    "\n",
    "gs_clf = GridSearchCV(pipeline, parameters, n_jobs=-1, scoring=scoring)\n",
    "gs_clf = gs_clf.fit(X, y)\n",
    "\n",
    "print(\"Best score\", gs_clf.best_score_)\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score 0.144670050761\n",
      "clf: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "def my_custom_loss_func(y_test, y_pred):\n",
    "    return (f1_score(y_test, y_pred, pos_label=False) + f1_score(y_test, y_pred)) / 2 + recall_score(y_test, y_pred)\n",
    "\n",
    "scoring = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(2,2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', SVC(kernel='rbf', probability=True))\n",
    "])\n",
    "\n",
    "parameters = {'clf': [\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "#     MLPClassifier(max_iter=1000),\n",
    "    SGDClassifier(max_iter=1000),\n",
    "    RandomForestClassifier()\n",
    "]}\n",
    "\n",
    "gs_clf = GridSearchCV(pipeline, parameters, n_jobs=-1, cv=30, scoring=\"recall\")\n",
    "gs_clf = gs_clf.fit(X, y)\n",
    "\n",
    "print(\"Best score\", gs_clf.best_score_)\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
