{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>content</th>\n",
       "      <th>count</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Um recurso da Procuradoria-Geral da República ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>STF decide hoje se vídeo de Aécio explicando m...</td>\n",
       "      <td>http://www.sensacionalista.com.br/2017/09/26/s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Há uma certa magia em viajar de trem pela Grã-...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15 destinos para conhecer de trem</td>\n",
       "      <td>http://bit.ly/2g8k2XR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Site Lança Cardápio Fit/Light (low-carb) e é N...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Site Lança Cardápio Fit (low-carb) e é Nova Se...</td>\n",
       "      <td>http://g3noticias.com.br/site_lanca_cardapio_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A hashtag #posteseuviralata alcançou o topo Tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>A hashtag #posteseuviralata está enchendo o Tw...</td>\n",
       "      <td>http://bzfd.it/2yvqIu3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>\"O que não me explicaram no dia da entrevista ...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Mulher acusa laboratório Fleury de racismo por...</td>\n",
       "      <td>https://www.buzzfeed.com/tatianafarah/mulher-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Parabéns, você deveria ir ao cinema! Você sabe...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Você deveria ir ao cinema?</td>\n",
       "      <td>http://bzfd.it/2ysGJ3W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Aprovada em silêncio aos 45 minutos do segundo...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Em silêncio, reforma eleitoral criou censura n...</td>\n",
       "      <td>http://bzfd.it/2xl7lin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>Mas não espere que Kesha conte algum segredo d...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>Kesha falou sobre que tipo de amiga a Taylor S...</td>\n",
       "      <td>http://bzfd.it/2yrVggv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Segundo deu em primeira mão o colunista Ancelm...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Mudança na Rouanet proíbe a Bíblia, que está c...</td>\n",
       "      <td>http://www.sensacionalista.com.br/2017/10/06/m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Com as eleições presidenciais se aproximando, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Facebook retira comentários e deixa apenas bot...</td>\n",
       "      <td>http://www.sensacionalista.com.br/2017/10/06/f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id                                            content  count  id  \\\n",
       "0            5  Um recurso da Procuradoria-Geral da República ...      1   1   \n",
       "1            1  Há uma certa magia em viajar de trem pela Grã-...      1   2   \n",
       "2            3  Site Lança Cardápio Fit/Light (low-carb) e é N...      1   3   \n",
       "3            1  A hashtag #posteseuviralata alcançou o topo Tr...      1   4   \n",
       "4            1  \"O que não me explicaram no dia da entrevista ...      1   5   \n",
       "5            3  Parabéns, você deveria ir ao cinema! Você sabe...      1   6   \n",
       "6            1  Aprovada em silêncio aos 45 minutos do segundo...      1   7   \n",
       "7            3  Mas não espere que Kesha conte algum segredo d...      1   8   \n",
       "8            5  Segundo deu em primeira mão o colunista Ancelm...      1   9   \n",
       "9            5  Com as eleições presidenciais se aproximando, ...      1  10   \n",
       "\n",
       "                                               title  \\\n",
       "0  STF decide hoje se vídeo de Aécio explicando m...   \n",
       "1                  15 destinos para conhecer de trem   \n",
       "2  Site Lança Cardápio Fit (low-carb) e é Nova Se...   \n",
       "3  A hashtag #posteseuviralata está enchendo o Tw...   \n",
       "4  Mulher acusa laboratório Fleury de racismo por...   \n",
       "5                         Você deveria ir ao cinema?   \n",
       "6  Em silêncio, reforma eleitoral criou censura n...   \n",
       "7  Kesha falou sobre que tipo de amiga a Taylor S...   \n",
       "8  Mudança na Rouanet proíbe a Bíblia, que está c...   \n",
       "9  Facebook retira comentários e deixa apenas bot...   \n",
       "\n",
       "                                                 url  \n",
       "0  http://www.sensacionalista.com.br/2017/09/26/s...  \n",
       "1                              http://bit.ly/2g8k2XR  \n",
       "2  http://g3noticias.com.br/site_lanca_cardapio_f...  \n",
       "3                             http://bzfd.it/2yvqIu3  \n",
       "4  https://www.buzzfeed.com/tatianafarah/mulher-a...  \n",
       "5                             http://bzfd.it/2ysGJ3W  \n",
       "6                             http://bzfd.it/2xl7lin  \n",
       "7                             http://bzfd.it/2yrVggv  \n",
       "8  http://www.sensacionalista.com.br/2017/10/06/m...  \n",
       "9  http://www.sensacionalista.com.br/2017/10/06/f...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"http://fake-news-detector-api.herokuapp.com/links/all\")\n",
    "\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of biased samples 49\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df.dropna(subset=[\"title\"], inplace=True)\n",
    "df.dropna(subset=[\"content\"], inplace=True)\n",
    "\n",
    "df[\"is_biased\"] = [cid == 4 for cid in df[\"category_id\"]]\n",
    "\n",
    "X = df[[\"title\", \"content\"]]\n",
    "y = df[\"is_biased\"]\n",
    "\n",
    "print(\"Number of biased samples\", len(df[df[\"is_biased\"] == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.635 f1 0.6 positive_recall 0.924 total weighted 3.083 MultinomialNB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.644 f1 0.407 positive_recall 0.357 total weighted 1.765 BernoulliNB\n",
      "accuracy 0.74 f1 0.648 positive_recall 0.669 total weighted 2.726 MultiLayerPerceptron\n",
      "accuracy 0.689 f1 0.54 positive_recall 0.609 total weighted 2.446 KNN\n",
      "accuracy 0.763 f1 0.681 positive_recall 0.771 total weighted 2.985 SGDClassifier\n",
      "accuracy 0.858 f1 0.594 positive_recall 0.174 total weighted 1.8 RandomForest\n",
      "accuracy 0.735 f1 0.599 positive_recall 0.523 total weighted 2.381 DecisionTreeClassifier\n",
      "accuracy 0.772 f1 0.695 positive_recall 0.758 total weighted 2.983 SVC\n",
      "accuracy 0.699 f1 0.618 positive_recall 0.908 total weighted 3.132 VotingClassifier\n",
      "accuracy 0.694 f1 0.613 positive_recall 0.879 total weighted 3.065 VotingClassifier2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, make_scorer, recall_score\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def test_classifier(clf_):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion(\n",
    "            transformer_list=[\n",
    "                ('title', Pipeline([\n",
    "                  ('selector1', FunctionTransformer(lambda x: x['title'], validate=False)),\n",
    "                  ('vect1', CountVectorizer(ngram_range=(1, 1))),\n",
    "                  ('tfidf1', TfidfTransformer())\n",
    "                ])),\n",
    "                ('content', Pipeline([\n",
    "                  ('selector2', FunctionTransformer(lambda x: x['content'], validate=False)),\n",
    "                  ('vect2', CountVectorizer(ngram_range=(3, 3))),\n",
    "                  ('tfidf2', TfidfTransformer())\n",
    "                ]))\n",
    "            ],\n",
    "            transformer_weights={\n",
    "                'title': 1.0,\n",
    "                'content': 0.8,\n",
    "            },\n",
    "        )),\n",
    "        ('sampling', RandomUnderSampler()),\n",
    "        ('clf', clf_)\n",
    "    ])\n",
    "    \n",
    "    clf = pipeline.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    avg_f1 = (f1_score(y_test, y_pred, pos_label=False) + f1_score(y_test, y_pred)) / 2\n",
    "    positive_recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, avg_f1, positive_recall\n",
    "    \n",
    "    \n",
    "def test_classifier_avg(name, clf):\n",
    "    times = 3\n",
    "    total_accuracy = 0\n",
    "    total_f1 = 0\n",
    "    total_positive_recall = 0\n",
    "    \n",
    "    for i in range(0, times):\n",
    "        accuracy, f1, positive_recall = test_classifier(clf)\n",
    "        total_accuracy += accuracy\n",
    "        total_f1 += f1\n",
    "        total_positive_recall += positive_recall\n",
    "    \n",
    "    print(\"accuracy\", round(total_accuracy / times, 3),\n",
    "          \"f1\", round(total_f1 / times, 3),\n",
    "          \"positive_recall\", round(total_positive_recall / times, 3),\n",
    "          \"total weighted\", round((total_accuracy + total_f1 + total_positive_recall * 2) / times, 3),\n",
    "          name\n",
    "         )\n",
    "\n",
    "\n",
    "test_classifier_avg(\"MultinomialNB\", MultinomialNB())\n",
    "test_classifier_avg(\"BernoulliNB\", BernoulliNB())\n",
    "test_classifier_avg(\"MultiLayerPerceptron\", MLPClassifier(solver='adam', max_iter=1000))\n",
    "test_classifier_avg(\"KNN\", KNeighborsClassifier())\n",
    "test_classifier_avg(\"SGDClassifier\", SGDClassifier(max_iter=1000))\n",
    "test_classifier_avg(\"RandomForest\", RandomForestClassifier())\n",
    "test_classifier_avg(\"DecisionTreeClassifier\", DecisionTreeClassifier())\n",
    "test_classifier_avg(\"SVC\", SVC(kernel='rbf', probability=True))\n",
    "test_classifier_avg(\"VotingClassifier\", VotingClassifier(estimators=[\n",
    "            ('MultinomialNB', MultinomialNB()),\n",
    "            (\"MultiLayerPerceptron\", MLPClassifier(solver='adam', max_iter=1000)),\n",
    "            (\"SVC\", SVC(kernel='rbf', probability=True))\n",
    "        ]))\n",
    "test_classifier_avg(\"VotingClassifier2\", VotingClassifier(estimators=[\n",
    "            ('MultinomialNB', MultinomialNB()),\n",
    "            (\"MultiLayerPerceptron\", MLPClassifier(solver='adam', max_iter=1000)),\n",
    "            (\"SDG\", SGDClassifier(max_iter=1000))\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10bdd4ae0, file \"/usr...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/Cellar/python3/3.6.1/Frameworks/Pytho...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/Cellar/python3/3.6.1/Frameworks/Pytho...lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/C.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10bdd4ae0, file \"/usr...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/Cellar/python3/3.6.1/Frameworks/Pytho...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/Cellar/python3/3.6.1/Frameworks/Pytho...lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/C.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 29, 10, 37, 41, 832074, tzinfo=tzlocal()), 'msg_id': 'A7A00FAAAC164F66AD7298686A40D6FE', 'msg_type': 'execute_request', 'session': '3E21D163BB1043BE8A95D0D94B724EED', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A7A00FAAAC164F66AD7298686A40D6FE', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'3E21D163BB1043BE8A95D0D94B724EED']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 29, 10, 37, 41, 832074, tzinfo=tzlocal()), 'msg_id': 'A7A00FAAAC164F66AD7298686A40D6FE', 'msg_type': 'execute_request', 'session': '3E21D163BB1043BE8A95D0D94B724EED', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A7A00FAAAC164F66AD7298686A40D6FE', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'3E21D163BB1043BE8A95D0D94B724EED'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 29, 10, 37, 41, 832074, tzinfo=tzlocal()), 'msg_id': 'A7A00FAAAC164F66AD7298686A40D6FE', 'msg_type': 'execute_request', 'session': '3E21D163BB1043BE8A95D0D94B724EED', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A7A00FAAAC164F66AD7298686A40D6FE', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/rchaves/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/rchaves/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.FunctionDef object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.For object>], cell_name='<ipython-input-27-6ca40c2dd04f>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1148d1978, execution_..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x10d006f60, file \"<ipython-input-27-6ca40c2dd04f>\", line 22>\n        result = <ExecutionResult object at 1148d1978, execution_..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/rchaves/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x10d006f60, file \"<ipython-input-27-6ca40c2dd04f>\", line 22>, result=<ExecutionResult object at 1148d1978, execution_..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x10d006f60, file \"<ipython-input-27-6ca40c2dd04f>\", line 22>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.model_selection import train_test_s...iased samples\", len(df[df[\"is_biased\"] == True]))', 'import pandas as pd\\n\\ndf = pd.read_json(\"http://f...-detector-api.herokuapp.com/links/all\")\\n\\ndf[0:10]', 'from sklearn.model_selection import train_test_s...iased samples\", len(df[df[\"is_biased\"] == True]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.model_selection import train_test_s...ed samples\", len(df[df[\"is_biased\"] == True]))\\n\\nX', 'from sklearn.model_selection import train_test_s...iased samples\", len(df[df[\"is_biased\"] == True]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', ...], ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.model_selection import train_test_s...iased samples\", len(df[df[\"is_biased\"] == True]))', 'import pandas as pd\\n\\ndf = pd.read_json(\"http://f...-detector-api.herokuapp.com/links/all\")\\n\\ndf[0:10]', 'from sklearn.model_selection import train_test_s...iased samples\", len(df[df[\"is_biased\"] == True]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.model_selection import train_test_s...ed samples\", len(df[df[\"is_biased\"] == True]))\\n\\nX', 'from sklearn.model_selection import train_test_s...iased samples\", len(df[df[\"is_biased\"] == True]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', ...], ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/Users/rchaves/Projects/fake-news-detector/robinho/notebooks/<ipython-input-27-6ca40c2dd04f> in <module>()\n     17     return (f1_score(y_test, y_pred, pos_label=False) + f1_score(y_test, y_pred)) / 2 + recall_score(y_test, y_pred)\n     18 \n     19 scoring = make_scorer(my_custom_loss_func, greater_is_better=True)\n     20 \n     21 gs_clf = GridSearchCV(pipeline, parameters, n_jobs=-1, scoring=scoring)\n---> 22 gs_clf = gs_clf.fit(X, y)\n     23 \n     24 print(\"Best score\", gs_clf.best_score_)\n     25 \n     26 for param_name in sorted(parameters.keys()):\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ring=make_scorer(my_custom_loss_func), verbose=0), X=                                                ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns], y=0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool, groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X =                                                 ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns]\n        y = 0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Oct 29 10:37:42 2017\nPID: 68774              Python 3.6.1: /Users/rchaves/tensorflow/bin/python3\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]),                                                 ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns], 0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool, {'score': make_scorer(my_custom_loss_func)}, array([ 87,  88,  89,  91,  92,  94,  96,  97,  ...79, 280, 281, 282, 283, 284, 285, 286, 287, 288]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  95, 128,\n       129, 138, 163, 164, 165, 166]), 0, {'clf__activation': 'relu', 'clf__solver': 'lbfgs'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]),                                                 ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns], 0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool, {'score': make_scorer(my_custom_loss_func)}, array([ 87,  88,  89,  91,  92,  94,  96,  97,  ...79, 280, 281, 282, 283, 284, 285, 286, 287, 288]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  95, 128,\n       129, 138, 163, 164, 165, 166]), 0, {'clf__activation': 'relu', 'clf__solver': 'lbfgs'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]), X=                                                ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns], y=0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool, scorer={'score': make_scorer(my_custom_loss_func)}, train=array([ 87,  88,  89,  91,  92,  94,  96,  97,  ...79, 280, 281, 282, 283, 284, 285, 286, 287, 288]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  95, 128,\n       129, 138, 163, 164, 165, 166]), verbose=0, parameters={'clf__activation': 'relu', 'clf__solver': 'lbfgs'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=0.1,\n       verbose=False, warm_start=False))])>\n        X_train =                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns]\n        y_train = 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]), X=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool, **fit_params={})\n    237         -------\n    238         self : Pipeline\n    239             This estimator\n    240 \n    241         \"\"\"\n--> 242         Xt, yt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        yt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...=0.1,\n       verbose=False, warm_start=False))])>\n        X =                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns]\n        y = 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool\n    243         if self._final_estimator is not None:\n    244             self._final_estimator.fit(Xt, yt, **fit_params)\n    245         return self\n    246 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]), X=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool, **fit_params={})\n    196                 # Fit or load from cache the current transfomer\n    197                 if (hasattr(cloned_transformer, \"transform\") or\n    198                         hasattr(cloned_transformer, \"fit_transform\")):\n    199                     Xt, fitted_transformer = fit_transform_one_cached(\n    200                         cloned_transformer, None, Xt, yt,\n--> 201                         **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'sampling': {}, 'tfidf': {}, 'vect': {}}\n        name = 'vect'\n    202                 elif hasattr(cloned_transformer, \"sample\"):\n    203                     Xt, yt, fitted_transformer = fit_sample_one_cached(\n    204                         cloned_transformer, Xt, yt,\n    205                         **fit_params_steps[name])\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x1107b70d0>), *args=(CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None,                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None,                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py in _fit_transform_one(transformer=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), weight=None, X=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool, **fit_params={})\n    588 \n    589 \n    590 def _fit_transform_one(transformer, weight, X, y,\n    591                        **fit_params):\n    592     if hasattr(transformer, 'fit_transform'):\n--> 593         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method CountVectorizer.fit_transform of C...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        X =                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns]\n        y = 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool\n        fit_params = {}\n    594     else:\n    595         res = transformer.fit(X, y, **fit_params).transform(X)\n    596     # if we have a weight for this transformer, multiply output\n    597     if weight is None:\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool)\n    864         max_df = self.max_df\n    865         min_df = self.min_df\n    866         max_features = self.max_features\n    867 \n    868         vocabulary, X = self._count_vocab(raw_documents,\n--> 869                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in _count_vocab(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], fixed_vocab=False)\n    806 \n    807         if not fixed_vocab:\n    808             # disable defaultdict behaviour\n    809             vocabulary = dict(vocabulary)\n    810             if not vocabulary:\n--> 811                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n    812                                  \" contain stop words\")\n    813 \n    814         j_indices = np.asarray(j_indices, dtype=np.intc)\n    815         indptr = np.frombuffer(indptr, dtype=np.intc)\n\nValueError: empty vocabulary; perhaps the documents only contain stop words\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 437, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py\", line 242, in fit\n    Xt, yt, fit_params = self._fit(X, y, **fit_params)\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py\", line 201, in _fit\n    **fit_params_steps[name])\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\", line 362, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py\", line 593, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 869, in fit_transform\n    self.fixed_vocabulary_)\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\", line 811, in _count_vocab\n    raise ValueError(\"empty vocabulary; perhaps the documents only\"\nValueError: empty vocabulary; perhaps the documents only contain stop words\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Oct 29 10:37:42 2017\nPID: 68774              Python 3.6.1: /Users/rchaves/tensorflow/bin/python3\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]),                                                 ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns], 0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool, {'score': make_scorer(my_custom_loss_func)}, array([ 87,  88,  89,  91,  92,  94,  96,  97,  ...79, 280, 281, 282, 283, 284, 285, 286, 287, 288]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  95, 128,\n       129, 138, 163, 164, 165, 166]), 0, {'clf__activation': 'relu', 'clf__solver': 'lbfgs'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]),                                                 ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns], 0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool, {'score': make_scorer(my_custom_loss_func)}, array([ 87,  88,  89,  91,  92,  94,  96,  97,  ...79, 280, 281, 282, 283, 284, 285, 286, 287, 288]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  95, 128,\n       129, 138, 163, 164, 165, 166]), 0, {'clf__activation': 'relu', 'clf__solver': 'lbfgs'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]), X=                                                ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns], y=0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool, scorer={'score': make_scorer(my_custom_loss_func)}, train=array([ 87,  88,  89,  91,  92,  94,  96,  97,  ...79, 280, 281, 282, 283, 284, 285, 286, 287, 288]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  95, 128,\n       129, 138, 163, 164, 165, 166]), verbose=0, parameters={'clf__activation': 'relu', 'clf__solver': 'lbfgs'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=0.1,\n       verbose=False, warm_start=False))])>\n        X_train =                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns]\n        y_train = 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]), X=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool, **fit_params={})\n    237         -------\n    238         self : Pipeline\n    239             This estimator\n    240 \n    241         \"\"\"\n--> 242         Xt, yt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        yt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...=0.1,\n       verbose=False, warm_start=False))])>\n        X =                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns]\n        y = 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool\n    243         if self._final_estimator is not None:\n    244             self._final_estimator.fit(Xt, yt, **fit_params)\n    245         return self\n    246 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]), X=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool, **fit_params={})\n    196                 # Fit or load from cache the current transfomer\n    197                 if (hasattr(cloned_transformer, \"transform\") or\n    198                         hasattr(cloned_transformer, \"fit_transform\")):\n    199                     Xt, fitted_transformer = fit_transform_one_cached(\n    200                         cloned_transformer, None, Xt, yt,\n--> 201                         **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'sampling': {}, 'tfidf': {}, 'vect': {}}\n        name = 'vect'\n    202                 elif hasattr(cloned_transformer, \"sample\"):\n    203                     Xt, yt, fitted_transformer = fit_sample_one_cached(\n    204                         cloned_transformer, Xt, yt,\n    205                         **fit_params_steps[name])\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x1107b70d0>), *args=(CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None,                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None,                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py in _fit_transform_one(transformer=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), weight=None, X=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool, **fit_params={})\n    588 \n    589 \n    590 def _fit_transform_one(transformer, weight, X, y,\n    591                        **fit_params):\n    592     if hasattr(transformer, 'fit_transform'):\n--> 593         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method CountVectorizer.fit_transform of C...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        X =                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns]\n        y = 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool\n        fit_params = {}\n    594     else:\n    595         res = transformer.fit(X, y, **fit_params).transform(X)\n    596     # if we have a weight for this transformer, multiply output\n    597     if weight is None:\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool)\n    864         max_df = self.max_df\n    865         min_df = self.min_df\n    866         max_features = self.max_features\n    867 \n    868         vocabulary, X = self._count_vocab(raw_documents,\n--> 869                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in _count_vocab(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], fixed_vocab=False)\n    806 \n    807         if not fixed_vocab:\n    808             # disable defaultdict behaviour\n    809             vocabulary = dict(vocabulary)\n    810             if not vocabulary:\n--> 811                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n    812                                  \" contain stop words\")\n    813 \n    814         j_indices = np.asarray(j_indices, dtype=np.intc)\n    815         indptr = np.frombuffer(indptr, dtype=np.intc)\n\nValueError: empty vocabulary; perhaps the documents only contain stop words\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sun Oct 29 10:37:42 2017\nPID: 68774              Python 3.6.1: /Users/rchaves/tensorflow/bin/python3\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]),                                                 ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns], 0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool, {'score': make_scorer(my_custom_loss_func)}, array([ 87,  88,  89,  91,  92,  94,  96,  97,  ...79, 280, 281, 282, 283, 284, 285, 286, 287, 288]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  95, 128,\n       129, 138, 163, 164, 165, 166]), 0, {'clf__activation': 'relu', 'clf__solver': 'lbfgs'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]),                                                 ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns], 0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool, {'score': make_scorer(my_custom_loss_func)}, array([ 87,  88,  89,  91,  92,  94,  96,  97,  ...79, 280, 281, 282, 283, 284, 285, 286, 287, 288]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  95, 128,\n       129, 138, 163, 164, 165, 166]), 0, {'clf__activation': 'relu', 'clf__solver': 'lbfgs'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]), X=                                                ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns], y=0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool, scorer={'score': make_scorer(my_custom_loss_func)}, train=array([ 87,  88,  89,  91,  92,  94,  96,  97,  ...79, 280, 281, 282, 283, 284, 285, 286, 287, 288]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  95, 128,\n       129, 138, 163, 164, 165, 166]), verbose=0, parameters={'clf__activation': 'relu', 'clf__solver': 'lbfgs'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=0.1,\n       verbose=False, warm_start=False))])>\n        X_train =                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns]\n        y_train = 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]), X=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool, **fit_params={})\n    237         -------\n    238         self : Pipeline\n    239             This estimator\n    240 \n    241         \"\"\"\n--> 242         Xt, yt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        yt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...=0.1,\n       verbose=False, warm_start=False))])>\n        X =                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns]\n        y = 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool\n    243         if self._final_estimator is not None:\n    244             self._final_estimator.fit(Xt, yt, **fit_params)\n    245         return self\n    246 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]), X=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool, **fit_params={})\n    196                 # Fit or load from cache the current transfomer\n    197                 if (hasattr(cloned_transformer, \"transform\") or\n    198                         hasattr(cloned_transformer, \"fit_transform\")):\n    199                     Xt, fitted_transformer = fit_transform_one_cached(\n    200                         cloned_transformer, None, Xt, yt,\n--> 201                         **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'sampling': {}, 'tfidf': {}, 'vect': {}}\n        name = 'vect'\n    202                 elif hasattr(cloned_transformer, \"sample\"):\n    203                     Xt, yt, fitted_transformer = fit_sample_one_cached(\n    204                         cloned_transformer, Xt, yt,\n    205                         **fit_params_steps[name])\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x1107b70d0>), *args=(CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None,                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None,                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py in _fit_transform_one(transformer=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), weight=None, X=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool, **fit_params={})\n    588 \n    589 \n    590 def _fit_transform_one(transformer, weight, X, y,\n    591                        **fit_params):\n    592     if hasattr(transformer, 'fit_transform'):\n--> 593         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method CountVectorizer.fit_transform of C...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        X =                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns]\n        y = 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool\n        fit_params = {}\n    594     else:\n    595         res = transformer.fit(X, y, **fit_params).transform(X)\n    596     # if we have a weight for this transformer, multiply output\n    597     if weight is None:\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool)\n    864         max_df = self.max_df\n    865         min_df = self.min_df\n    866         max_features = self.max_features\n    867 \n    868         vocabulary, X = self._count_vocab(raw_documents,\n--> 869                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in _count_vocab(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], fixed_vocab=False)\n    806 \n    807         if not fixed_vocab:\n    808             # disable defaultdict behaviour\n    809             vocabulary = dict(vocabulary)\n    810             if not vocabulary:\n--> 811                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n    812                                  \" contain stop words\")\n    813 \n    814         j_indices = np.asarray(j_indices, dtype=np.intc)\n    815         indptr = np.frombuffer(indptr, dtype=np.intc)\n\nValueError: empty vocabulary; perhaps the documents only contain stop words\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6ca40c2dd04f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mgs_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mgs_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 638\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x10bdd4ae0, file \"/usr...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/Cellar/python3/3.6.1/Frameworks/Pytho...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/Cellar/python3/3.6.1/Frameworks/Pytho...lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/C.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x10bdd4ae0, file \"/usr...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/Cellar/python3/3.6.1/Frameworks/Pytho...ges/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/Cellar/python3/3.6.1/Frameworks/Pytho...lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/C.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 29, 10, 37, 41, 832074, tzinfo=tzlocal()), 'msg_id': 'A7A00FAAAC164F66AD7298686A40D6FE', 'msg_type': 'execute_request', 'session': '3E21D163BB1043BE8A95D0D94B724EED', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A7A00FAAAC164F66AD7298686A40D6FE', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'3E21D163BB1043BE8A95D0D94B724EED']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 29, 10, 37, 41, 832074, tzinfo=tzlocal()), 'msg_id': 'A7A00FAAAC164F66AD7298686A40D6FE', 'msg_type': 'execute_request', 'session': '3E21D163BB1043BE8A95D0D94B724EED', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A7A00FAAAC164F66AD7298686A40D6FE', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'3E21D163BB1043BE8A95D0D94B724EED'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 10, 29, 10, 37, 41, 832074, tzinfo=tzlocal()), 'msg_id': 'A7A00FAAAC164F66AD7298686A40D6FE', 'msg_type': 'execute_request', 'session': '3E21D163BB1043BE8A95D0D94B724EED', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': 'A7A00FAAAC164F66AD7298686A40D6FE', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/Users/rchaves/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from sklearn.model_selection import GridSearchCV... % (param_name, gs_clf.best_params_[param_name]))', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/Users/rchaves/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.FunctionDef object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.For object>], cell_name='<ipython-input-27-6ca40c2dd04f>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 1148d1978, execution_..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x10d006f60, file \"<ipython-input-27-6ca40c2dd04f>\", line 22>\n        result = <ExecutionResult object at 1148d1978, execution_..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/Users/rchaves/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x10d006f60, file \"<ipython-input-27-6ca40c2dd04f>\", line 22>, result=<ExecutionResult object at 1148d1978, execution_..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x10d006f60, file \"<ipython-input-27-6ca40c2dd04f>\", line 22>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.model_selection import train_test_s...iased samples\", len(df[df[\"is_biased\"] == True]))', 'import pandas as pd\\n\\ndf = pd.read_json(\"http://f...-detector-api.herokuapp.com/links/all\")\\n\\ndf[0:10]', 'from sklearn.model_selection import train_test_s...iased samples\", len(df[df[\"is_biased\"] == True]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.model_selection import train_test_s...ed samples\", len(df[df[\"is_biased\"] == True]))\\n\\nX', 'from sklearn.model_selection import train_test_s...iased samples\", len(df[df[\"is_biased\"] == True]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', ...], ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.model_selection import train_test_s...iased samples\", len(df[df[\"is_biased\"] == True]))', 'import pandas as pd\\n\\ndf = pd.read_json(\"http://f...-detector-api.herokuapp.com/links/all\")\\n\\ndf[0:10]', 'from sklearn.model_selection import train_test_s...iased samples\", len(df[df[\"is_biased\"] == True]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.model_selection import train_test_s...ed samples\", len(df[df[\"is_biased\"] == True]))\\n\\nX', 'from sklearn.model_selection import train_test_s...iased samples\", len(df[df[\"is_biased\"] == True]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', 'from sklearn.feature_extraction.text import Coun...SDG\", SGDClassifier(max_iter=1000))\\n#         ]))', ...], ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/Users/rchaves/Projects/fake-news-detector/robinho/notebooks/<ipython-input-27-6ca40c2dd04f> in <module>()\n     17     return (f1_score(y_test, y_pred, pos_label=False) + f1_score(y_test, y_pred)) / 2 + recall_score(y_test, y_pred)\n     18 \n     19 scoring = make_scorer(my_custom_loss_func, greater_is_better=True)\n     20 \n     21 gs_clf = GridSearchCV(pipeline, parameters, n_jobs=-1, scoring=scoring)\n---> 22 gs_clf = gs_clf.fit(X, y)\n     23 \n     24 print(\"Best score\", gs_clf.best_score_)\n     25 \n     26 for param_name in sorted(parameters.keys()):\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ring=make_scorer(my_custom_loss_func), verbose=0), X=                                                ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns], y=0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool, groups=None, **fit_params={})\n    633                                   return_train_score=self.return_train_score,\n    634                                   return_n_test_samples=True,\n    635                                   return_times=True, return_parameters=False,\n    636                                   error_score=self.error_score)\n    637           for parameters, (train, test) in product(candidate_params,\n--> 638                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X =                                                 ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns]\n        y = 0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool\n        groups = None\n    639 \n    640         # if one choose to see train score, \"out\" will contain train score info\n    641         if self.return_train_score:\n    642             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Oct 29 10:37:42 2017\nPID: 68774              Python 3.6.1: /Users/rchaves/tensorflow/bin/python3\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]),                                                 ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns], 0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool, {'score': make_scorer(my_custom_loss_func)}, array([ 87,  88,  89,  91,  92,  94,  96,  97,  ...79, 280, 281, 282, 283, 284, 285, 286, 287, 288]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  95, 128,\n       129, 138, 163, 164, 165, 166]), 0, {'clf__activation': 'relu', 'clf__solver': 'lbfgs'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]),                                                 ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns], 0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool, {'score': make_scorer(my_custom_loss_func)}, array([ 87,  88,  89,  91,  92,  94,  96,  97,  ...79, 280, 281, 282, 283, 284, 285, 286, 287, 288]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  95, 128,\n       129, 138, 163, 164, 165, 166]), 0, {'clf__activation': 'relu', 'clf__solver': 'lbfgs'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]), X=                                                ...ct. 28, 1886, that t...  \n\n[289 rows x 2 columns], y=0      False\n1      False\n2      False\n3      Fa...  False\nName: is_biased, Length: 289, dtype: bool, scorer={'score': make_scorer(my_custom_loss_func)}, train=array([ 87,  88,  89,  91,  92,  94,  96,  97,  ...79, 280, 281, 282, 283, 284, 285, 286, 287, 288]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...,  95, 128,\n       129, 138, 163, 164, 165, 166]), verbose=0, parameters={'clf__activation': 'relu', 'clf__solver': 'lbfgs'}, fit_params={}, return_train_score=True, return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    432 \n    433     try:\n    434         if y_train is None:\n    435             estimator.fit(X_train, **fit_params)\n    436         else:\n--> 437             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(memory=No...=0.1,\n       verbose=False, warm_start=False))])>\n        X_train =                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns]\n        y_train = 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool\n        fit_params = {}\n    438 \n    439     except Exception as e:\n    440         # Note fit time as time until error\n    441         fit_time = time.time() - start_time\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]), X=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool, **fit_params={})\n    237         -------\n    238         self : Pipeline\n    239             This estimator\n    240 \n    241         \"\"\"\n--> 242         Xt, yt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        yt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...=0.1,\n       verbose=False, warm_start=False))])>\n        X =                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns]\n        y = 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool\n    243         if self._final_estimator is not None:\n    244             self._final_estimator.fit(Xt, yt, **fit_params)\n    245         return self\n    246 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('vect', Count...n=0.1,\n       verbose=False, warm_start=False))]), X=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool, **fit_params={})\n    196                 # Fit or load from cache the current transfomer\n    197                 if (hasattr(cloned_transformer, \"transform\") or\n    198                         hasattr(cloned_transformer, \"fit_transform\")):\n    199                     Xt, fitted_transformer = fit_transform_one_cached(\n    200                         cloned_transformer, None, Xt, yt,\n--> 201                         **fit_params_steps[name])\n        fit_params_steps = {'clf': {}, 'sampling': {}, 'tfidf': {}, 'vect': {}}\n        name = 'vect'\n    202                 elif hasattr(cloned_transformer, \"sample\"):\n    203                     Xt, yt, fitted_transformer = fit_sample_one_cached(\n    204                         cloned_transformer, Xt, yt,\n    205                         **fit_params_steps[name])\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x1107b70d0>), *args=(CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None,                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), None,                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool)\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imblearn/pipeline.py in _fit_transform_one(transformer=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), weight=None, X=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool, **fit_params={})\n    588 \n    589 \n    590 def _fit_transform_one(transformer, weight, X, y,\n    591                        **fit_params):\n    592     if hasattr(transformer, 'fit_transform'):\n--> 593         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method CountVectorizer.fit_transform of C...w+\\\\b',\n        tokenizer=None, vocabulary=None)>\n        X =                                                 ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns]\n        y = 89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool\n        fit_params = {}\n    594     else:\n    595         res = transformer.fit(X, y, **fit_params).transform(X)\n    596     # if we have a weight for this transformer, multiply output\n    597     if weight is None:\n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in fit_transform(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], y=89     False\n90     False\n91     False\n93     Fa...  False\nName: is_biased, Length: 192, dtype: bool)\n    864         max_df = self.max_df\n    865         min_df = self.min_df\n    866         max_features = self.max_features\n    867 \n    868         vocabulary, X = self._count_vocab(raw_documents,\n--> 869                                           self.fixed_vocabulary_)\n        self.fixed_vocabulary_ = False\n    870 \n    871         if self.binary:\n    872             X.data.fill(1)\n    873 \n\n...........................................................................\n/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/feature_extraction/text.py in _count_vocab(self=CountVectorizer(analyzer='word', binary=False, d...\\w+\\\\b',\n        tokenizer=None, vocabulary=None), raw_documents=                                                ...ct. 28, 1886, that t...  \n\n[192 rows x 2 columns], fixed_vocab=False)\n    806 \n    807         if not fixed_vocab:\n    808             # disable defaultdict behaviour\n    809             vocabulary = dict(vocabulary)\n    810             if not vocabulary:\n--> 811                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n    812                                  \" contain stop words\")\n    813 \n    814         j_indices = np.asarray(j_indices, dtype=np.intc)\n    815         indptr = np.frombuffer(indptr, dtype=np.intc)\n\nValueError: empty vocabulary; perhaps the documents only contain stop words\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(2,2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('sampling', RandomUnderSampler()),\n",
    "    ('clf', MLPClassifier(max_iter=10000, solver=\"adam\", activation=\"relu\"))\n",
    "])\n",
    "\n",
    "parameters = {'clf__solver': [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "              'clf__activation': [\"relu\", \"tanh\"],\n",
    "}\n",
    "\n",
    "def my_custom_loss_func(y_test, y_pred):\n",
    "    return (f1_score(y_test, y_pred, pos_label=False) + f1_score(y_test, y_pred)) / 2 + recall_score(y_test, y_pred)\n",
    "\n",
    "scoring = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
    "\n",
    "gs_clf = GridSearchCV(pipeline, parameters, n_jobs=-1, scoring=scoring)\n",
    "gs_clf = gs_clf.fit(X, y)\n",
    "\n",
    "print(\"Best score\", gs_clf.best_score_)\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score 0.144670050761\n",
      "clf: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "def my_custom_loss_func(y_test, y_pred):\n",
    "    return (f1_score(y_test, y_pred, pos_label=False) + f1_score(y_test, y_pred)) / 2 + recall_score(y_test, y_pred)\n",
    "\n",
    "scoring = make_scorer(my_custom_loss_func, greater_is_better=True)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(2,2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', SVC(kernel='rbf', probability=True))\n",
    "])\n",
    "\n",
    "parameters = {'clf': [\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "#     MLPClassifier(max_iter=1000),\n",
    "    SGDClassifier(max_iter=1000),\n",
    "    RandomForestClassifier()\n",
    "]}\n",
    "\n",
    "gs_clf = GridSearchCV(pipeline, parameters, n_jobs=-1, cv=30, scoring=\"recall\")\n",
    "gs_clf = gs_clf.fit(X, y)\n",
    "\n",
    "print(\"Best score\", gs_clf.best_score_)\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
